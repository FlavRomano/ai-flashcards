---
tags:
  - "#card"
  - logic
  - aif
cards-deck: aif
---

#flashcards/aif/logic1

### What's a Knowledge-Based Agent?
?
It's an agent that **create** and **maintain** an internal representation of the world.

#### How they generate new knowledge about the world?
?
They use **inference**, a form of reasoning.

#### How they decide which action to take?
?
They use their representations

#### What kind of information Knowledge base contains?
?
KB contains domain specific information. Is a set of sentences expressed in a formal language.


#### Which approaches we distinguish?
?
- declarative
	- encoding **what the agent knows**
- procedural
	- encoding **what the agent does**


#### In which language the sentences are expressed?
?
Sentences in formal language.


#### What's the Tell-Ask paradigm?
?
The way we interact with a knowledge base.
- **tell** new knowledge to the $KB$
- **ask** known information or infer it

##### Which operation adds new knowledge?
?
The tell operation.

##### Which operation adds retrieve knowledge?
?
The ask operation. Can also infer new information

##### What's the inference engine?
?
Is the tool that provides 
- a domain agnostic algorithm
- to derive a **new sentence** from existing KB

##### What algorithm provides the inference engine?
?
Domain agnostic algorithm to derive new sentences from existing KB.

#### How a KB-agent inference an action from a perception?
?
We use 
1. Tell to create a sentence from the perception
2. then Ask to make an action based to the current KB and time $t$
3. from the action made at 2. and time $t$ we create a sentence
4. we Tell to the KB the new action in sentence form (PERFORMED).

##### Steps of the algorithm
?
$t$ is a static counter
1. perception to sentence, then tell sentence to KB
2. make sentence to query KB for action at instant $t$, then ask KB to retrieve the correct action
3. action to sentence, then tell sentence to KB
4. increment $t$
5. return action

##### Which function returns the action that should be taken at time $t$?
?
Ask does, but first needs a query sentence`Make-Action-Query` to retrieve/infer the action from the KB.

##### What `Make-Percept-Sentence` do?
?
Convert the current percept and time into a sentence for KB.

##### What `Make-Action-Query` do?
?
Create a sentence query to retrieve/infer from KB related to time $t$.

##### What `Make-Action-Sentence` do?
?
Given an action, builds a sentence to state that the action was performed.

#### What's a model?
?
Mathematical abstraction, a model $m$ satisfies sentence $\alpha$ if $\alpha$ is true in $m$. 

##### What denotes $M(\alpha)$?
?
$M(\alpha)$ is the set of all models where $\alpha$ is true.

##### How is Entailment $\alpha\vDash\beta$ defined in terms of models?
?
One sentence $\alpha$ logically follows another $\beta$. 
- $\alpha$ entails $\beta \iff$ in every model $\alpha$ is true, $\beta$ is also true $$\alpha \vDash \beta \iff M(\alpha) \subseteq M(\beta)$$

##### How entailment is verified?
?
Via model checking ![[Pasted image 20260110150146.png]] enumerate all possible models and check whether $\alpha_1$ is true in all $M$ in which KB is true $$M(KB)\subseteq M(\alpha_1)$$

##### What's model checking?
?
Way to verify entailment, $\alpha$ entails $\beta \iff$ in every model in $M(\beta)$ $\alpha$ is true

#### What's logical equivalence $\alpha \equiv \beta$?
?
If $\alpha$ logically follows $\beta$ and viceversa, so if **they entail each other**.

#### When is a sentence valid?
?
When is true in all models $$A \lor \lnot A$$.

#### When is a sentence satisfiable?
?
If is true in some model.

#### When is a sentence satisfiable?
?
If is true in **NO** model.

##### Is unsatisfiability connected to inference?
?
Yes, $KB\vdash_i \alpha$ means
- sentence $\alpha$ is derived from KB by algorithm $i$
	- it connects with unsatisfiability by $$KB \vDash \alpha \equiv (KB \lor \lnot \alpha)$$
		- to prove that $KB$ entails $\alpha$
			- we need to show that is impossible for the KB and negation of goal $\lnot\alpha$  to be true at the same time **CONTRADDICTION**
- SAT is a powerful tool for inference

##### What inference of $\alpha$ with KB mean?
?
That sentence $\alpha$ is derived from $KB$ using algorithm $i$

##### What is $i$ in inference?
?
The algorithm used to derive $\alpha$ from KB.

##### What's soundness?
?
If $KB\vdash\alpha$ then $KB\vDash\alpha$
- if we can derive $\alpha$ from $KB$
	- then $\alpha$ is logical consequence of KB
- The algorithm find true facts.

##### What's completeness?
?
If $KB\vDash\alpha$ then $KB\vdash\alpha$
- if $\alpha$ is a logic consequence of KB
	- then $\alpha$ can be derived from KB
- The algorithm can find all truths

#### What's propositional logic?
?
It's the simplest logic. 
- **Syntax**
	- It uses atomic sentences and logical connectives.
- **Semantics**
	- Those expressions are evaluated using
		- recursion
		- truth tables


##### What are $P_1$ and $P_2$?
?
They are proposition symbols AKA atomic sentences.

##### Which are the possible connection for sentences $S_1$ and $S_2$?
Given two sentences:
- negation of one
- conjunction
- disjunction
- implication
- biconditional

##### What's propositional logic semantics duty?
?
To evaluate complex sentences via recursion and Truth tables.

#### What's inference by enumeration?
?
It's a basic form of model checking. To demonstrate inference $KB\vDash\alpha$ we 
- generate all possible models (assignments) $$2^n$$
- check in which models KB is true
	- check that $\alpha$ is also true in all such models

##### As inference algorithm, is inference by enumeration good? hind: soundness and completeness
?
It's naive model checking. This is sound and complete but has exponential time complexity $$O(2^n)$$

##### What is the time complexity of Inference by Enumeration?
?
$$O(2^n)$$

#### What's theorem proving?
?
To prove something we can apply inference rule.
- starting from KB
- apply inference rules
- derive the goal

##### Why theorem proving could be seen as a form of search?
?
We search the optimal inference rules to derive the goal.

##### What's a clause?
?
A clause is **disjunction of literals** $$(A\lor B)$$

##### What's CNF? hint: Conjunctive Normal Form 
?
A CNF sentence is a conjunction of clauses $$(A\lor B) \land (C\lor \lnot D)$$

###### Does any proposition can be converted to CNF?
?
Yes, following proposition logic rules

##### What's the resolution rule?
?
Is a inference tool used to derive new facts from existing ones. It operates on sentences expressed in CNF.
- take two clauses that contain complementary literals
	- a literal and its negation $P,\lnot P$
- combine them into a single new clause called **RESOLVENT**
	- by canceling out the complementary pair

##### What's the unit resolution rule?
?
Simpler resolution rule where one of the parent clauses is a unit clause. 
Given $l_1\lor\ldots\lor l_k$ and $m$ complementary literals
- we can derive the new clause **RESOLVENT**
- as the original clause without the literal $l_i$ $$l_1\lor\ldots\lor l_{i-1} \lor l_{i+1} \lor\ldots\lor l_k$$

##### What's the unit resolution rule?
?
Generalization of the unit resolution rule with both parent clauses have multiple literals.

##### What's resolution inference?
?
Showing inference implies showing contradiction of negation $$KB\vDash\alpha\iff KB\land \lnot\alpha\text{ is unsatisfiable }$$.

##### Is resolution inference sound and complete?
?
Yes, both. They derive any true statement (complete) and only true things (sound)

##### How resolution inference works?
?
![[Pasted image 20260110162450.png]]
1. Convert $KB\lor\lnot\alpha$ to CNF
2. For all clauses pairs
	1. apply resolution rule to all clauses
	2. generate new clauses
		1. if generates empty clause
		2. then KB entails $\alpha$ since we generated contradiction
3. If contradiction are not found, then KB does not entail $\alpha$

#### What's a Horn Clause?
?
Is a conjunction of clauses
- with a most one positive symbol
- e.g $$\lnot A \lor \lnot B \lor C$$

##### Why Horn Clause are important?
?
They can be written as **body**$\implies$**head**, inference is linear in time wrt KB size. $$(\lnot A \lor \lnot B \lor C)\equiv (A\land B \implies C)$$

##### What's a limitation of Horn form?
?
We cannot convert any propositional logic sentence into Horn form. **Not UNIVERSAL**

##### What's forward chaining?
?
Data driven reasoning exploiting Horn clauses simplicity. Starting from KB, applies Modus Ponens to add new facts to the KB (**CHAINING**) until $\alpha$ is generated.
- return true if can generates $\alpha$
- else false

##### What's modus ponens? Why is core of forward chaining?
?
Modus ponens is a rule $(p\implies q)\land p\vdash q$. 
- Forward chain uses propositions in horn form that are $$(\lnot A \lor \lnot B \lor C)\equiv (A\land B \implies C)$$ so it's easy to apply modus ponens to infer some proposition. 
- It's the rule that enables chaining until goal is reached
	- it ensures soundness

##### What's forward chaining time complexity?
?
It is **linear** in time complexity wrt the size of the Knowledge Base $O(n)$ where $n$ is the size of the KB). 
- This efficiency is possible because it requires the KB to be in **Horn form**

##### What's backward chaining?
?
 It is a **goal-directed** reasoning algorithm. 
 - It starts from the query (the goal) and works backward. 
 - If the query is not a known fact, it identifies rules that conclude the query (the "heads") 
 - and then tries to prove the premises of those rules (the "bodies") iteratively.

###### What's backward chaining starting point?
?
It starts from the **query** (the desired goal or conclusion)

###### Why backward chaining is cheaper than forward one?
?
Because it is goal-directed, 
- it only explores **relevant paths** needed to prove the specific query. 
- Forward chaining, by contrast, 
	- derives all possible conclusions from the data
	- many of which may be irrelevant to the current goal

#### Describe Wumpus PEAS
?
- **Performance measure:** +1000 for gold, -1000 for death, -1 per step, -10 for using the arrow.
- **Environment:** A 4x4 grid where squares adjacent to the Wumpus are smelly, squares adjacent to pits are breezy, and gold glitters.
- **Actuators:** Left turn, Right turn, Forward, Grab, Shoot.
- **Sensors:** Breeze (B), Glitter (G), Smell (S).

#### Describe Wumpus logic
It consists of the rules an agent uses to represent the world.
- It also includes strategies
- e.g if an agent cannot move without more knowledge, 
	- it can "shoot straight"
	- if the Wumpus was there, it is now dead and the path is safe

#### Why we move from propositional logic to first order logic?
?
Because **propositional logic is not that expressive**. It is difficult to represent general rules about many objects (like "all pits cause a breeze in adjacent squares") without writing a separate sentence for every single square in the grid