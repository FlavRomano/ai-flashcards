---
tags:
  - card
  - evolutionary
  - aif
cards-deck: aif::evo2
---
# Evolutionary II
##  Genetic algorithm #card  
- Is a **general purpose protocol**
	- based on a population
	- mutations are **rare**
	- driven by **recombination**

### What represents an individual? #card 
- Each individual is represented by a **BIT STRING** called **CHROMOSOME**
	- represents the individual genotype
		- e.g $0100$ 
	- it's the internal representation
		- is manipulated during mutation and crossover

### What's a phenotype? #card 
Given a genotype,
- a phenotype is what the genotype builds 
	- e.g genotype $0100$, phenotype: $$01=blue,\quad00=elephant$$
- it is the external expression 
	- that interacts with the environment 
	- and gets evaluated

### What's the core loop of Genetic Algorithm? #card 
1. Selection
2. Crossover
3. Mutation

#### How selection phase works? #card 
- From the population
	- pick parents based on a fitness function $$P:p_1,p_2,\dots,p_n$$

##### Which type of selection is used? #card 
- Comma selection
	- the $\mu$ best kids will replace the parents

#### How crossover phase works? #card 
- Is the process of combining the genetic information of two parents 
	- to produce new offspring
- It simulates biological reproduction to mix traits
	- hoping the children inherit the best parts of both parents.

##### How 1-point crossover works? #card 
- Choose $k\in[0,\#\text{chromosomes})$ 
- you cut both parents at $k$ spot and swap the tails
![[Pasted image 20260105174337.png]]

##### How 2-point crossover works? #card 
- Choose $k_1,k_2\in[0,\#\text{chromosomes})$ 
- you cut both parents at two spots and swap the **middle segment** only.![[Pasted image 20260105174405.png]]

#### Why input encoding is crucial? #card 
- Input encoding is something related to the domain
- One wrong input encoding could make the problem unsolvable
	- e.g hamming cliff considering binary encoding for integers $$[0,15]\to [0000,1111]$$

##### What's hamming cliff? #card 
- Mutation are rare in Genetic Algorithms
- Moving from 7 to 8 requires **a lot of mutations** $$7=0111, \;8 = 1000$$
	- flipping all bits
	- so it makes **statistically impossible** to mutate from 7 to 8
	- that's not good

#### What's direct encoding? #card 
- When each element in the genotype
	- maps **a feature in the phenotype** 
	- e.g 3 phenotype feature $$\underbrace{\overbrace{00}^{feature}\;11\;10}_{genotype}$$

##### What's the problem of direct encoding? #card 
- It's too simple, it doesn't capture patterns
- For each phenotype feature we have a genotype representation
- Scales bad
	- e.g a separate DNA code for
		- each finger
		- each eye
		- each arm...

#### What's indirect encoding? #card 
- Indirect encoding allows modularity and symmetry
- Encodes the **rules** for the developments of phenotype
	- one encoding that when expressed can lead to the development of several parts

#### For which encoding the search space is narrow? #card 
- Indirect encoding
	- One feature in the genotype can be linked to several feature combinations in the phenotype.
	- So the search space
		- is much smaller then the phenotype space
		- there isn't 1:1 mapping

#### Describe search space of direct encoding #card 
- 1:1 mapping between phenotype feature and genotype representation
	- search space has same dimension of the phenotype space
		- one feature, one dimension
		- not feasible, it doesn't scale well

#### What's CPPNs? #card 
- Compositional Pattern Producing Networks
	- popular indirect encoding
	- mathematical function graph ![[Pasted image 20260106095202.png]]
		- input: phenotypical space coordinates $$(x,y)$$
		- output: phenotypical value $$f(x,y)$$ 
	- $f$ is the encoding
		- is the same for all the inputs
		- could be a composition of function $$f = \sin \circ \text{ abs } \circ \text{ mod}$$ ![[Pasted image 20260106095533.png]]
	- graph's nodes are not user choice
		- we evolve the graph structure

##### How CPPN evolve? #card 
- We start with a small graph
	- just inputs and outputs nodes
	- no hidden layer
- We add complexity over time (**complexification**)
		- add neurons and connections
		- the solution would be as complex as it needs to be
			- avoid unnecessary nodes
			- avoid overcomplicated solution
- This is how NEAT (NeuroEvolution of Augmenting Topologies) works

#### What's NEAT? #card 
- It's a genetic algorithm that 
	- evolves network topologies
	- every simulation starts with simple networks
		- just inputs and outputs nodes
	- adds complexity over time, if needed
		- neurons, hidden layer

##### Does NEAT use direct encoding? #card 
- Yes, NEAT use a **list of genes** to store the network ![[Pasted image 20260106101021.png]] both nodes and connections are represented by genes, with some properties.
- Each node  is represented by one gene, same for connections.
	- 1:1 $\implies$ direct encoding

##### What contains each connection gene in NEAT? #card 
Each gene contains: ![[Pasted image 20260106101021.png]]
1. **In-Node & Out-Node** 
	- Which neurons does this connect?
2. **Weight** 
	- How strong is the connection?
3. **Enabled/Disabled** 
	- A switch to turn the connection off without deleting it 
	- useful if a mutation goes wrong and we want to revert
4. **Innovation Number** 


##### What's the innovation number in NEAT? #card 
- Is a historical marker
	- when structural mutations happens
		- if it's the first time that the connection is appearing
			- then the global innovation counter gets incremented
			- we add the connection with the new innovation number
		- else, we already seen it in the past
			- we use the same innovation number
			- it's a way to track down the gene origin for crossover

##### Which are NEAT's mutation? #card 
- NEAT evolves the network through mutations
	- add a connection
	- add a node

##### How NEAT adds a connection? #card 
- connect two existing node with a randomly weighted connection

##### How NEAT adds a node? #card 
- not easy, the new node needs to be part of the flow
1. Select an existing **enabled** connection $$(X,Z)$$
2. **Disable** that connection $$\cancel{(X,Z)}$$
3. Creates a new node in the middle $Y$
	- in-weight=1
	- out-weight=previous weight of $(X,Z)$
4. Creates two new connections $$(X,Y) \longleftrightarrow (Y,Z)$$

###### Why splits connection? #card 
- To preserve the flow
	- adds non-linearity (a neuron) in the middle 
	- the network can learn new functions

##### What's NEAT speciation? #card 
- NEAT groups the population into species **based on how similar their topologies are**
	- It calculates a distance score $\delta$ in the topology space
		- based on how many genes don't match (Excess/Disjoint genes) 
		- and how different the weights are
	- Fitness for an individual $i$ of species $s$ $$f_i^s = \frac{f_i}{\# s}$$ is the average distance to the other fitnesses values in the same niche 
- You only compete against your own species.
	- The old, simple networks compete against other old, simple networks. 
	- The new, complex networks compete against other new, complex networks.
- Gives a grace period to optimize their weights
	- before competing with more robust network

###### What problem NEAT speciation tries to mitigate? #card 
- When a network evolves a new node
	- the weights connecting this new node are random
	- network will likely perform worse than its parents in the short term. 
	- In a standard algorithm, would be killed off immediately because its fitness dropped

###### What's distance $\delta$? #card 
- $\delta$ is a distance score in the topology space
	- based on how many genes don't match (Excess/Disjoint genes) 
	- and how different the weights are

###### How distance $\delta$ is computed? #card 
- $\delta$ relates $$\delta = \underbrace{\frac{c_1E}{N} + \frac{c_2D}{N}}_{\text{topology}} + \overbrace{c_3 \Delta W}^{weight}$$
	- topology distance ![[Pasted image 20260106110233.png]]
		- NEAT aligns the two genomes based on their **Innovation Numbers**
		- $E$ excess genes
			- count of genes that do not match 
			- and are historically "newer"
		- $D$ disjoint genes
			- count of genes that do not match 
			- but are within the range of **common innovation numbers** (we know them from the past)
		- $N$ number of genes in the larger genome
	- weight distance $$\Delta W$$
		- For genes share the same innovation number 
			- the algorithm calculates **the average difference in their connection weights** 

#### What's HyperNEAT? Why is used? #card 
- NEAT use direct encoding
	- cannot generalize, can't scale well
	- list of genes, 1:1 encoding
- HyperNEAT use indirect encoding via CPPN ![[Pasted image 20260106111247.png]]
	- evolves a CPPN
	- To decide the connection weight between **Node A** $$(x_1​,y_1​)$$ and **Node B** at $$(x_2​,y_2​)$$
	- the system takes those **4 coordinates** and feeds them into the CPPN $$(x_1​,y_1​, x_2​,y_2)$$
	- The CPPN outputs the strength of the connection between A and B $$w$$
	- detect regularities in visual patterns

#### What's the novelty search intuition? #card 
- The objective is to survive and replicate
	- no task-based fitness
- Stop looking for the solution
	- we don't aim to the fittest individual
	- otherwise we could stuck to a local optimum
- We stop looking at the Genotype (DNA) and start looking at the **Behavior** (Phenotype)

##### How can we define the behaviour of an individual? #card 
- By numerical encoding
	- e.g: Maze navigation = path of cartesian coordinates $$[(1,2),(2,3),..,(5,5)]$$

##### How novelty search keeps on archive of phenotypes? #card 
- Novelty search memorize already explored solution into and **archive**
- The archive is a list of previous individuals 
	- that were highly novel

##### How we define novelty? #card 
- Novelty is the sparseness $\rho(x)$ in the behavior space 

##### How $\rho(x)$ sparseness is computed? #card 
As the **k-Nearest Neighbors (k-NN)** distance $$\rho(x) = \frac{1}{k}\sum_{i=1}^k d(x,n_i)$$ 
1. Take new individual $x$
2. Find $k$ individuals in the populations that are most similar to $x$
3. Calculate average distance $d$ to them
	- if $d$ **small**
		- $x$ is in a crowd
		- is doing what everyone else do (OPPOSITE OF NOVELTY)
			- **LOW FITNESS**
	- if $d$ **high**
		- $x$ is far away from known behaviors
		- is doing a unique behavior
			- **HIGH FITNESS**

##### Which $\rho(x)$ novelty search seeks? High, low #card 
- Large $\rho(x)$, novelty search seeks unique behaviors
	- $x$ should be far away from known behaviors
- If $\rho(x)$ surpass $\rho_{\text{min}}$ threshold
	- $x$ is added to the **archive**

##### What's a stepping stone? #card 
- Stepping stone are individuals that does not relates at all with the final solution
- Novelty search adores them
	- they compose paths to solutions that otherwise would be discarded

##### What's a limitation of novelty search? #card 
- Novelty Search explores everything
	- including useless behaviors
	- it focuses to **Diversity** rather than **Quality**

#### What's NSLC? #card 
- Novelty Search with Local Competition
- Focuses on
	- Diversity
		- be different
		- use Novelty Search 
	- Quality
		- be better than neighbors (niche)
		- compute the individual’s task-based fitness for quality

#### What problem solves Quality Diversity? #card 
- It solves Novelty Search limitation
	- be different at the point to prefer useless behavior to better one
- Quality Diversity are a family of optimization approaches 
	- between task-based fitness and novelty search

#### What's MapElites? #card 
- Multi-dimensional Archive of Phenotypic Elites
- the most important algorithm in the **Quality Diversity** family
> What is the best solution for **every possible variation** of the behavior?

##### How MapElites archive works? #card 
- The archive is **Feature Map** of phenotypic elites ![[Pasted image 20260106120834.png]] 
	- Space of possible behaviors (dimensions) is equally important
	- You slice these dimensions into a grid of bins
	- The goal 
		- is to fill as many of these bins as possible 
		- with the **elite** (the best individual found so far) for that specific bin.

##### MapElites loop #card 
1. Selection
	- select parents **uniformly at random from the occupied bins.**
	- each parent is an elite of that niche
2. Mutation
	- mutation and creation of offspring $x$
3. Evaluation
	- compute behavior `behavior(x)`
		- niche determination
		- in which bin we should insert $x$
	- compute performance `performance(x)`
		- how well the offspring is at the task
4. Competition
	- if the bin is empty
		- $x$ goes there
	- if the bin is occupied by $y$
		- if $x$ performance are better 
			- then discard $y$ and put $x$
		- else discard $x$ and keep $y$

##### How do we evaluate MapElites work? #card 
- There is a metric for QD algorithm evaluation called **QD-Score** $$\text{QD-Score}=\sum_{i=1}^{bins} Fitness_i$$ we sum Fitness of every elites in the map.
- If the score is **HIGH** then MapElites did a good job balancing
	- Novelty search for diversity
	- Bins optimization for task-based fitness quality

#### How evolvability judge a parent? #card 
- how parent's children are diverse between each other

##### How evolvability search works? #card 
> Will this parent have interesting children?
1. Select candidate parent from population
2. Generate fake offspring 
	- "fake" because we won't actually keep them in the population
		- they are just for testing
	- apply random mutation on them
3. Measure diversity
	- Look at the behaviors of these fake children wrt archive
	- how well they generalize to a new environment without further adaptation
4. Select the parent with the most diverse fake offspring wins


##### Why evolvability is important to generalize? Hint: OOD #card 
- Solutions with high evolvability
	- can adapt better to OOD (unseen data)
	- with just few mutations

##### Which individuals Evolvability Search prefers? #card 
- The one with unique behaviors
	- parent contains the genetic code for many possible futures

##### Compare different search: Evolvability Search, Novelty Search, Object based search #card 
|Feature|Objective-Based|Novelty Search|Evolvability Search|
|---|---|---|---|
|**Driver**|Task Fitness (Quality)|Behavioral Sparseness (Diversity)|Offspring Diversity (Potential)|
|**Focus**|The Present (Current performance)|The Past (Archive of history)|The Future (Hypothetical children)|
|**Main Risk**|**Deception:** Getting stuck in local optima.|**Aimlessness:** Exploring useless behaviors (like running in circles).|**Cost:** Requires simulating many "fake" children per parent.|
|**Stucking probability**|High (DNA becomes fragile).|Medium.|Low (DNA remains flexible).|
![[Pasted image 20260106151129.png]]

##### Which Evolutionary Strategy could be applied to Evolvability Search to deal with fake offspring evolution? #card 
- Evolutionary Search is expensive because of simulation of fake offsprings
	- Instead of fake offsprings 
	- we can maintain just a Isotropic Gaussian population distribution $$\pi\sim N(\mu, \sigma)$$
- Then maximize via gradient descent a function expressing evolvability $$F(\vartheta)=\sum_j \mathbb{E}_{z\sim\pi}\left[ (B(z) - \mu)^2 \right]$$
	- $B(z)$ is the behaviour of the best child $z$
		- $z\sim\pi$ because the offspring is made from $\pi$ distribution
	- $\mu$ average behaviour
	- $(B(z) - \mu)^2$ is the **variance**
		- how far the best child $z$ moves from average $\mu$
- Maximizing the variance $$\max \;\underbrace{(B(z) - \mu)^2}_{variance}$$
	- pushes the population distribution to "expand" 
	- and cover as much behavioral space as possible.