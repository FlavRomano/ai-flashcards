---
tags:
  - "#card"
  - aif
  - probability
---

#flashcards/aif/prob1

### Sources of Uncertainty
?
Real-world problems contain uncertainty primarily due to three factors:
1.  **Partial observability:** The agent cannot perceive the full state of the world.
2.  **Nondeterminism:** Actions may have random or unexpected outcomes.
3.  **Adversaries:** Other agents may hide information or act against the agent.

### Failure of Logic in Uncertainty
?
Strict logical rules (e.g., "Toothache $\Rightarrow$ Cavity") fail in uncertain domains because to make the rule "true," you would need a **logically exhaustive** list of all exceptions (gum problems, abscess, etc.). This approach is impossible (infinite list) and doomed to fail.

### Three Reasons for Complexity Explosion
?
Large domains (like medical diagnosis) fail under strict logic due to:
1.  **Laziness:** Too much work to list all antecedents/consequents for an exceptionless rule.
2.  **Theoretical Ignorance:** No complete scientific theory exists for the domain.
3.  **Practical Ignorance:** Even knowing the rules, we may not have run all necessary tests for a specific patient.

### Agent's Knowledge State
?
In uncertain environments, an agent does not hold absolute truths. Instead, it has a **degree of belief** regarding relevant sentences.

### Rational Decision Factors
?
A rational decision depends on two factors:
1.  The **relative importance** of various goals (Utility).
2.  The **likelihood** that those goals will be achieved (Probability).

### Bayesian View of Probability
?
The **Bayesian view** treats probability as a subjective **degree of belief** about an event. It starts with a **prior** belief and updates it to a **posterior** belief based on observed evidence (**likelihood**).

### Frequentist View of Probability
?
The **Frequentist view** assumes there is a "true" objective probability value that can be estimated by repeatedly observing multiple realizations of an event.

### Utility Theory
?
**Utility Theory** deals with the quality of an outcome being useful. It posits that every state has a degree of usefulness (utility) for the agent, allowing the agent to express preferences among outcomes.

### Decision Theory
?
**Decision Theory** is the combination of **Utility Theory** (Preferences) and **Probability Theory** (Beliefs).

### Principle of Maximum Expected Utility (MEU)
?
An agent is rational if and only if it chooses the action that yields the highest **expected utility**, averaged over all possible outcomes of the action.

### Ontological vs. Epistemological Perspectives
?
*   **Ontological:** Both probability and logic agree that the world *is* a certain way (a proposition is strictly true or false).
*   **Epistemological:** They differ in what the agent *knows*. Probability assumes the agent has a continuous degree of belief, whereas logic assumes the agent believes a proposition is definitively true or false.

### The Sample Space ($\Omega$)
?
The set of all possible worlds or models. These worlds must be **mutually exclusive** and **exhaustive**.

### Axioms of Probability
?
1.  $0 \leq P(w) \leq 1$ (Probabilities are between 0 and 1).
2.  $\sum_{w \in \Omega} P(w) = 1$ (The sum of probabilities of all possible worlds is 1).

### Prior Probability
?
Also called **unconditional probability**. It represents the degree of belief in a proposition in the absence of any other information.

### Probability of Negation
?
$P(\neg a) = 1 - P(a)$

### Inclusion-Exclusion Principle (Or)
?
$P(a \lor b) = P(a) + P(b) - P(a \land b)$

### Conditional Probability Formula
?
$$P(a|b) = \frac{P(a \land b)}{P(b)}$$
(The probability of $a$ given that $b$ has occurred).

### Product Rule
?
Derived from conditional probability:
$P(a \land b) = P(a|b)P(b)$

### Independence
?
Two variables $a$ and $b$ are independent if:
$P(a|b) = P(a)$
Or equivalently:
$P(a \land b) = P(a)P(b)$

### Factored Representation
?
A method where a possible world is represented by a set of **variable/value pairs** (random variables and their assignments), allowing for concise definition of probability distributions.

### Joint Probability Distribution
?
A table or function assigning probabilities to every possible combination of values for all random variables. For variables $A$ and $B$, it is written as $P(A=a \land B=b)$ or $P(a, b)$.

### Marginalization
?
The process of extracting the probability of a subset of variables by summing over the variables not in the subset.
$$P(A) = \sum_b P(A, B=b)$$

### General Inference Formula
?
To find the probability of Query variables ($Y$) given Evidence ($E$), summing over Hidden variables ($H$):
$$P(Y|E = e) = \alpha \sum_h P(Y, E=e, H=h)$$
(Where $\alpha$ is a normalizing constant).

### Complexity of Exact Inference
?
Using the full joint distribution with $n$ variables and $d$ values per variable:
*   **Worst-case complexity:** $O(d^n)$ (Exponential).
*   **Storage:** The table has $d^n$ entries.

### Reducing Complexity via Independence
?
If all variables are mutually independent, the joint probability can be factored into separate products. This reduces the size/complexity from $O(d^n)$ to **$O(dn)$** (Linear).

### Bayes' Rule Formula
?
$$P(b|a) = \frac{P(a|b) P(b)}{P(a)}$$

### Bayes' Rule Causal Interpretation
?
Bayes' rule allows us to derive a **Diagnostic** probability ($P(\text{Cause}|\text{Effect})$) from a **Causal** probability ($P(\text{Effect}|\text{Cause})$) and the Prior ($P(\text{Cause})$).

### Effect of Low Prior Probability
?
If a condition (e.g., Meningitis) has a very low prior probability, even a positive symptom (high likelihood) may result in a low posterior probability. Several observations are often needed to overcome a low prior.

### Conditional Independence
?
$A$ and $B$ are conditionally independent given $C$ if:
$P(A, B | C) = P(A | C)P(B | C)$
Meaning: If we know $C$, knowing $B$ gives us no extra information about $A$.

### Naïve Bayes Model Structure
?
A model where a single **Cause** node points to multiple **Effect** nodes. It assumes that all effects are **conditionally independent** given the cause.

### Naïve Bayes Formula
?
$$P(\text{Cause}|\text{Effects}) = \alpha P(\text{Cause}) \prod_j P(\text{Effect}_j | \text{Cause})$$
This scales linearly with the number of effects.

### Decision Ranking vs. Exact Probability
?
To make a rational decision (e.g., where to move next), an agent does not necessarily need the exact probability values or the normalizing constant ($\alpha$). It only needs the relative **rank** of likelihoods to determine which action is safest.