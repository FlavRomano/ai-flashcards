---
tags:
  - "#card"
  - aif
  - multi-agent
---

#flashcards/aif/multiAgent

### The Single Agent Assumption
?
The simplifying assumption used in early AI courses where only one agent is sensing, planning, and acting. This ignores the reality that most real-world scenarios involve multiple agents.

### Benevolent Agent Assumption
?
The assumption made in a "One Decision Maker / Multiple Actors" environment. It assumes that agents (or body parts) will do exactly what they are told because they share a centralized control system and goals (e.g., a robot with two arms).

### Multi-Agent Coordination Problem
?
A situation where multiple decision makers share the same goal but must synchronize their behavior to achieve it (e.g., a team of doctors, or moving a heavy object together).

### Game Theory Definition
?
The theory of strategic decision-making where each player takes into account the potential behaviors and choices of other players.

### Cooperative vs. Non-Cooperative Games
?
**Cooperative:** Cooperation arises from binding agreements (contracts/communication) among agents.
**Non-cooperative:** No explicit agreements exist. Cooperation (if it happens) emerges from spontaneous activity.

### Mechanism Design
?
A use of Game Theory where the goal is to design the *environment* itself (e.g., traffic rules, auction systems) so that when agents maximize their individual utility, they also maximize the system's overall utility.

### Interleaved Execution Model
?
A planning model that stops concurrency by executing actions one at a time (atomically). A plan must be correct for *all* possible sequential orderings (interleavings) of the agents' actions.

### Computational Complexity of Interleaved Execution
?
The number of possible resulting plans is **exponential** with respect to the number of actors and actions, because the system must account for every possible permutation of action orders (e.g., A1 before B1, or B1 before A1).

### True Concurrency (Planning)
?
A planning model that maintains only a partial ordering between actions. It does not define an order across all pairs of actions (e.g., A1 must happen before B2, but A2 and B1 have no constraints relative to each other).

### Joint Action
?
Used in **Perfect Synchronization** planning. It is a vector $a = [a_1, ..., a_n]$ representing the simultaneous actions of all $n$ agents at a specific time step.

### Concurrent Action Constraint (Negative)
?
A logical constraint specifying that an action *cannot* be executed if another specific action is happening simultaneously.
*Example:* Two tennis players cannot `Hit` the ball at the exact same time.

### Concurrent Action Constraint (Positive)
?
A logical constraint specifying that an action *can only* be executed if another agent performs a specific action simultaneously.
*Example:* An agent can only `Carry` a heavy cooler if another agent is also `Carry`-ing it.

### Plan Recognition
?
A coordination method where one agent observes a few actions of another agent to infer their entire plan, allowing them to adapt without explicit communication.

### Normal Form Game Components
?
1. A set of $n$ **Players**.
2. A set of **Actions** each agent can execute.
3. A **Payoff Function** (or matrix) describing the utility received by each agent after all simultaneous actions are taken.

### Pure Strategy
?
A deterministic policy in Game Theory. In a normal-form game, it corresponds to selecting a single, specific action to be taken.

### Mixed Strategy
?
A randomized or stochastic policy where an agent selects an action based on a specific probability distribution (e.g., play "Rock" 30% of the time, "Paper" 70%).

### Strongly Dominant Strategy
?
A strategy $s$ is strongly dominant if it yields a better outcome for the player than any other strategy $s'$, regardless of what the other players choose.

### Weakly Dominant Strategy
?
A strategy $s$ is weakly dominant if it is better than $s'$ for *at least one* choice of the opponent, and no worse (equal) for all other choices.

### Dominant Strategy Equilibrium
?
The outcome reached when all players choose their dominant strategy. It is stable because no player has any incentive to change their choice.

### Nash Equilibrium
?
A strategy profile where no player can unilaterally change their strategy and receive a higher payoff, assuming the other players do *not* change their strategies. Each player is playing the **best response** to the others.

### Existence of Nash Equilibria
?
Nash equilibria may not always exist for **Pure Strategies** (e.g., Rock-Paper-Scissors), but they **always** exist for **Mixed Strategies**.

### Pareto Optimality
?
An outcome is Pareto Optimal if it is impossible to increase the utility of one agent without decreasing the utility of another agent. If an outcome is *not* Pareto Optimal, utility is being "wasted."

### Utilitarian Social Welfare
?
A measure of group success calculated by the **sum** of all players' utilities for a given outcome. It does not consider inequality.

### Egalitarian Social Welfare
?
A measure of group success that focuses on the distribution of utility. It seeks to maximize the utility of the **worst-off** player (max-min approach).

### Prisoner's Dilemma Conflict
?
The conflict where the rational choice for individuals (Dominant Strategy/Nash Equilibrium) leads to an outcome (e.g., both testifying) that is **not** Pareto Optimal and results in lower Social Welfare than if they had cooperated.

### Complexity of Finding Equilibria
?
Finding a Nash Equilibrium via exhaustive search is **computationally intractable** in most cases, with a complexity of $O(\#actions^{\#players})$.